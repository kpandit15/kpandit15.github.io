# Kundan - Data Engineer

__ETL: Extract, Transform, Load... and Hope Nothing Breaks__

__Location:__ Bengaluru, Karnataka, India  
__Contact:__ [kpandit15@gmail.com](mailto:kpandit15@gmail.com)  
__LinkedIn:__ [linkedin.com/in/kundan-243217146](https://www.linkedin.com/in/kundan-243217146)

---

## Summary
6.5+ years of experience as a Data Engineer with a track record of driving operational efficiency and data-driven decision-making.

- Worked with 3 Fortune 500 companies (CITI Bank, Truist Bank, and Elevance Health) as clients in their Sustainability, Customer Experience, Marketing, and Claims domains
- Proficient in Python, SQL, with a strong emphasis on Spark and Pandas for processing large datasets and optimizing data workflows.
- Extensive experience in working with Spark, Hive, and Airflow, demonstrating expertise in big data processing and orchestration.
- Proficient in Python, complex SQL queries, and data modeling, and created data pipelines in Python.
- Skilled in AWS services including S3, Glue, Redshift, EMR, Lambda, EC2, and Athena, enabling cloud-based data engineering solutions.
- Designed and optimized MongoDB backend for efficient data retrieval from various data sources, showcasing a deep understanding of database optimization.
- Proficient in Tableau, with a track record of creating intuitive, accurate dashboards and data models for it.
- Committed to staying updated with emerging technologies, leveraging a passion for innovation to bring cutting-edge
solutions.
---

## Skills and Expertise
- __Languages:__ Python, SQL
- __FrameWork:__ Apache Spark, FastAPI, Streamlit
- __Data Tools:__ Tableau, Hive, SSMS, Airflow, Databricks, ADF
- __DevOps:__ Github Actions, Jenkins, Azure DevOps
- __Cloud:__ AWS, Azure


---

## Experience

### __Louis Dreyfus Company__
__Data Engineer__
_(November 2023 - Present | Bangalore Urban, Karnataka, India)_

Worked on a sustainability project to trace commodities from farm to destination port in compliance with the new EUDR
regulation.
- Processed data from multiple APIs using Spark and Databricks, stored it in a Data Lake, orchestrated workflows with
ADF, and exposed key data via FastAPI to support stakeholder access and ensure EU market eligibility.
- Skills: __Databricks, Python, SQL, Azure, AzureDevops, FastAPI, Jenkins__

### __Carelon Global Solutions__
__Senior Software Engineer__
_(August 2021 - September 2022 | Bengaluru, Karnataka, India)_

In Elevance Health worked on a claims automation project aimed at streamlining the claims process using machine
learning models.
- Built Streamlit dashboards integrated with MongoDB to provide model reasoning, enabling nurses to make informed
decisions.
- Skills: __Spreamlit, SQL, Python, MongoDB__

### __Fractal__
__Consultant__  
_(August 2021 - September 2022 | Bengaluru, Karnataka, India)_
Worked in the Customer Experience domain at Citibank, building Spark pipelines and dashboards to identify complaint
types and uncover hidden customer issues for improved service insights.
- Processed millions of records daily using Spark, stored them in the Hive data warehouse, and implemented end-to-end
orchestration with Apache Airflow.
- Skills: __Python, Spark, SQL, Hive, Data Warehousing, Airflow__

### __Infosys__
__Senior System Engineer__  
_(July 2018 - July 2021 | Mysore, Karnataka, India)_ 
Worked with Truist Bank to develop and maintain marketing campaign tracking pipelines, enabling efficient data
collection, performance analysis, and ROI measurement for targeted marketing initiatives.
- Skills: __Python, Spark, AWS, SQL, Hive, DB2, Control-M__

---

## Education
__ITM University, Gwalior__  
Bachelor of Technology - BTech, Computer Engineering (2014 - 2018)

---

## Portfolio

Check out my GitHub for projects and code samples: [GitHub Profile](#)

